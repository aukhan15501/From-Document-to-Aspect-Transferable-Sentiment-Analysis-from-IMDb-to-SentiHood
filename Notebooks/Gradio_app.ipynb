{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 0: Installs (Colab/Jupyter) </h1>"
      ],
      "metadata": {
        "id": "EiipYBLeOEzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"transformers>=4.35\" \"accelerate>=0.21\" gradio pandas"
      ],
      "metadata": {
        "id": "N15at-9oMnn2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 1: Imports & runtime setup </h1>"
      ],
      "metadata": {
        "id": "VsxOvWR4OJel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, traceback, torch, pandas as pd\n",
        "import gradio as gr\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Optional: silence external telemetry/wandb\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ],
      "metadata": {
        "id": "TVnxOiOFOZME"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 2: (Colab) Mount Google Drive </h1>"
      ],
      "metadata": {
        "id": "39ECH2lYOeQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "except Exception:\n",
        "    # Not in Colab; ignore.\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAbm8crRMncy",
        "outputId": "c6d67bc4-5dab-4746-d176-768703484a9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 3: Constants (paths, label sets, aspects) </h3>"
      ],
      "metadata": {
        "id": "StcMzptgOnVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDb (binary) best models you trained earlier (EDIT if your paths differ):\n",
        "IMDB_MODELS: Dict[str, str] = {\n",
        "    \"roberta-base\":            \"/content/drive/MyDrive/bert_imdb_sentiment_analysis/models/roberta-base/best_model\",\n",
        "    \"bert-base-uncased\":       \"/content/drive/MyDrive/bert_imdb_sentiment_analysis/models/bert-base-uncased/best_model\",\n",
        "    \"distilbert-base-uncased\": \"/content/drive/MyDrive/bert_imdb_sentiment_analysis/models/distilbert-base-uncased/best_model\",\n",
        "}\n",
        "\n",
        "# ABSA best models (produced by your ABSA training notebook):\n",
        "ABSA_ROOT = \"/content/drive/MyDrive/ABSA\"\n",
        "TRACKS = [\"TrackA\", \"TrackB\"]\n",
        "\n",
        "# Sentihood aspects & sentiments (4-way head expected for ABSA)\n",
        "ASPECTS = [\n",
        "    \"dining\",\"general\",\"green-nature\",\"live\",\"multicultural\",\"nightlife\",\n",
        "    \"price\",\"quiet\",\"safety\",\"shopping\",\"touristy\",\"transit-location\"\n",
        "]\n",
        "SENTIMENTS = [\"negative\", \"neutral\", \"positive\", \"none\"]\n",
        "SENT2ID = {s:i for i,s in enumerate(SENTIMENTS)}\n",
        "ID2SENT = {i:s for i,s in enumerate(SENTIMENTS)}\n",
        "\n",
        "# Regex to extract Sentihood-style LOCATION targets (kept for backwards-compat)\n",
        "TARGET_RX = re.compile(r\"LOCATION\\d+\", re.IGNORECASE)\n",
        "def extract_targets(text: str) -> List[str]:\n",
        "    ts = sorted(set(TARGET_RX.findall(text or \"\")))\n",
        "    # NOTE: If you do not want any fallback, return [] here instead of [\"LOCATION1\"].\n",
        "    return ts if ts else [\"LOCATION1\"]"
      ],
      "metadata": {
        "id": "ioyKbPzDMnRN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 4: Utilities: validate & discover checkpoints </h1>"
      ],
      "metadata": {
        "id": "ST3ApGRyPGcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WEIGHTS = {\"model.safetensors\", \"pytorch_model.bin\", \"tf_model.h5\", \"flax_model.msgpack\"}\n",
        "\n",
        "def _has_weights_dir(p: Optional[str]) -> bool:\n",
        "    if not p or not os.path.isdir(p): return False\n",
        "    try:\n",
        "        fs = set(os.listdir(p))\n",
        "        return bool(WEIGHTS & fs) and (\"config.json\" in fs)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def discover_imdb_models() -> Dict[str, str]:\n",
        "    out = {}\n",
        "    for k, p in IMDB_MODELS.items():\n",
        "        if _has_weights_dir(p):\n",
        "            out[k] = p\n",
        "    return out\n",
        "\n",
        "def discover_absa_models() -> Dict[str, Dict[str, str]]:\n",
        "    pretty = {\n",
        "        \"roberta-base\": \"RoBERTa Base\",\n",
        "        \"bert-base-uncased\": \"BERT Base Uncased\",\n",
        "        \"distilbert-base-uncased\": \"DistilBERT Base Uncased\"\n",
        "    }\n",
        "    found: Dict[str, Dict[str, str]] = {}\n",
        "    for t in TRACKS:\n",
        "        t_dir = os.path.join(ABSA_ROOT, t)\n",
        "        if not os.path.isdir(t_dir):\n",
        "            continue\n",
        "        per_track = {}\n",
        "        for sub in sorted(os.listdir(t_dir)):\n",
        "            best_dir = os.path.join(t_dir, sub, \"best\")\n",
        "            if _has_weights_dir(best_dir):\n",
        "                per_track[pretty.get(sub, sub)] = best_dir\n",
        "        if per_track:\n",
        "            found[t] = per_track\n",
        "    return found\n",
        "\n",
        "IMDB_FOUND = discover_imdb_models()              # { \"roberta-base\": \"/path/...\" , ... }\n",
        "ABSA_FOUND = discover_absa_models()              # { \"TrackA\": {\"RoBERTa Base\": \"/.../best\", ...}, \"TrackB\": {...} }\n",
        "\n",
        "# Display names for IMDb dropdown (hide raw paths)\n",
        "PRETTY_MAP = {\n",
        "    \"roberta-base\": \"RoBERTa Base\",\n",
        "    \"bert-base-uncased\": \"BERT Base Uncased\",\n",
        "    \"distilbert-base-uncased\": \"DistilBERT Base Uncased\",\n",
        "}\n",
        "imdb_display_to_path = {PRETTY_MAP.get(k, k): p for k, p in IMDB_FOUND.items()}\n",
        "IMDB_CHOICES = sorted(imdb_display_to_path.keys())"
      ],
      "metadata": {
        "id": "_-2cJB-HMnFW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 5: Device & robust model cache/loader </h1>"
      ],
      "metadata": {
        "id": "3qunQOeePQ_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "_cache: Dict[str, Tuple[AutoTokenizer, AutoModelForSequenceClassification]] = {}\n",
        "\n",
        "def _validate_checkpoint_dir(model_dir: str):\n",
        "    if not model_dir or not os.path.isdir(model_dir):\n",
        "        raise FileNotFoundError(f\"Path does not exist: {model_dir!r}\")\n",
        "    files = set(os.listdir(model_dir))\n",
        "    if \"config.json\" not in files:\n",
        "        raise FileNotFoundError(f\"Missing config.json in {model_dir}\")\n",
        "    if not (WEIGHTS & files):\n",
        "        raise FileNotFoundError(\n",
        "            f\"No weights file found in {model_dir}. Expected one of: {sorted(WEIGHTS)}\"\n",
        "        )\n",
        "\n",
        "def load_model(model_dir: str) -> Tuple[AutoTokenizer, AutoModelForSequenceClassification]:\n",
        "    \"\"\"Robust loader with validation and GPU→CPU fallback.\"\"\"\n",
        "    if model_dir in _cache:\n",
        "        return _cache[model_dir]\n",
        "\n",
        "    _validate_checkpoint_dir(model_dir)\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n",
        "\n",
        "    # Try GPU first, fall back to CPU if CUDA fails\n",
        "    try:\n",
        "        mdl = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        mdl.to(DEVICE).eval()\n",
        "    except Exception as e:\n",
        "        try:\n",
        "            mdl = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "            mdl.to(\"cpu\").eval()\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Failed to load model from {model_dir}: {e2}\") from e\n",
        "\n",
        "    _cache[model_dir] = (tok, mdl)\n",
        "    return tok, mdl"
      ],
      "metadata": {
        "id": "hYhJQNWQMm4_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 6: Inference helpers </h1>"
      ],
      "metadata": {
        "id": "2hJdb0qNQM9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def imdb_predict(text: str, model_dir: str) -> Tuple[str, float]:\n",
        "    text = str(text or \"\").strip()\n",
        "    if not text:\n",
        "        return \"—\", 0.0\n",
        "    tok, mdl = load_model(model_dir)\n",
        "    enc = tok(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "    enc = {k: v.to(mdl.device) for k, v in enc.items()}\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**enc).logits\n",
        "        probs = torch.softmax(logits, dim=-1).squeeze(0).cpu().numpy()\n",
        "    if probs.shape[-1] != 2:\n",
        "        raise ValueError(\n",
        "            f\"This IMDb checkpoint has {probs.shape[-1]} classes, expected 2. \"\n",
        "            f\"Did you select an ABSA model by mistake?\"\n",
        "        )\n",
        "    idx = int(probs.argmax())\n",
        "    label = \"positive\" if idx == 1 else \"negative\"\n",
        "    conf = float(probs[idx])\n",
        "    return label, conf\n",
        "\n",
        "def absa_table(text: str, model_dir: str, min_conf=0.60, min_margin=0.20, top_k: Optional[int]=6) -> pd.DataFrame:\n",
        "    text = str(text or \"\").strip()\n",
        "    if not text:\n",
        "        return pd.DataFrame(columns=[\"Aspect\",\"Target\",\"Label\",\"Confidence\"])\n",
        "\n",
        "    tok, mdl = load_model(model_dir)\n",
        "    SEP = tok.sep_token or \"[SEP]\"\n",
        "\n",
        "    targets = extract_targets(text)  # If you want NO fallback, change function to return [].\n",
        "    batch, meta = [], []\n",
        "    for t in targets:\n",
        "        for a in ASPECTS:\n",
        "            batch.append(\n",
        "                f\"Sentence: {text} {SEP} Target: {t} {SEP} Aspect: {a} {SEP} Task: classify sentiment for this target & aspect.\"\n",
        "            )\n",
        "            meta.append((t, a))\n",
        "\n",
        "    enc = tok(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
        "    enc = {k: v.to(mdl.device) for k, v in enc.items()}\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**enc).logits\n",
        "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "    if probs.shape[-1] != 4:\n",
        "        raise ValueError(\n",
        "            f\"This ABSA checkpoint has {probs.shape[-1]} classes, expected 4 \"\n",
        "            f\"(['negative','neutral','positive','none']). Did you select an IMDb model by mistake?\"\n",
        "        )\n",
        "\n",
        "    rows = []\n",
        "    for (t, a), p in zip(meta, probs):\n",
        "        p_none = float(p[SENT2ID[\"none\"]])\n",
        "        best_lbl, best_conf = None, -1.0\n",
        "        for lbl in (\"positive\",\"neutral\",\"negative\"):\n",
        "            c = float(p[SENT2ID[lbl]])\n",
        "            if c > best_conf:\n",
        "                best_lbl, best_conf = lbl, c\n",
        "        if best_conf >= min_conf and (best_conf - p_none) >= min_margin:\n",
        "            rows.append({\"Aspect\": a, \"Target\": t, \"Label\": best_lbl, \"Confidence\": round(best_conf, 3)})\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values(\"Confidence\", ascending=False)\n",
        "    if top_k is not None:\n",
        "        df = df.head(top_k)\n",
        "    return df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "-hVQwc5eMmqz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 7: Gradio callbacks </h1>"
      ],
      "metadata": {
        "id": "fdLECvZfQjIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _first_or_blank(xs: List[str]) -> str:\n",
        "    return xs[0] if xs else \"\"\n",
        "\n",
        "def absa_model_choices(track: str) -> List[str]:\n",
        "    if not track or track not in ABSA_FOUND:\n",
        "        return []\n",
        "    return sorted(list(ABSA_FOUND[track].keys()))  # display names only\n",
        "\n",
        "def on_track_change(track: str):\n",
        "    choices = absa_model_choices(track)\n",
        "    return gr.Dropdown(choices=choices, value=_first_or_blank(choices), interactive=True)\n",
        "\n",
        "def run_inference(\n",
        "    text: str,\n",
        "    imdb_display: str,\n",
        "    absa_track: str,\n",
        "    absa_display: str,\n",
        "    min_conf: float,\n",
        "    min_margin: float,\n",
        "    top_k: int,\n",
        "    imdb_manual: str,\n",
        "    absa_manual: str\n",
        "):\n",
        "    # IMDb\n",
        "    try:\n",
        "        imdb_dir = (imdb_manual or \"\").strip() or imdb_display_to_path.get(imdb_display or \"\", \"\")\n",
        "        if imdb_dir:\n",
        "            imdb_label, imdb_conf = imdb_predict(text, imdb_dir)\n",
        "            imdb_pretty = f\"{imdb_label.capitalize()} ({imdb_conf:.3f})\"\n",
        "        else:\n",
        "            imdb_pretty = \"No IMDb model selected.\"\n",
        "    except Exception as e:\n",
        "        imdb_pretty = \"ERROR: \" + str(e)\n",
        "\n",
        "    # ABSA\n",
        "    try:\n",
        "        absa_dir = (absa_manual or \"\").strip() or ABSA_FOUND.get(absa_track or \"\", {}).get(absa_display or \"\", \"\")\n",
        "        if absa_dir:\n",
        "            absa_df = absa_table(text, absa_dir, min_conf=min_conf, min_margin=min_margin, top_k=top_k)\n",
        "        else:\n",
        "            absa_df = pd.DataFrame([{\"Aspect\":\"—\",\"Target\":\"—\",\"Label\":\"No ABSA model selected.\",\"Confidence\":0.0}])\n",
        "    except Exception as e:\n",
        "        absa_df = pd.DataFrame([{\"Aspect\":\"ERROR\",\"Target\":\"—\",\"Label\":str(e),\"Confidence\":0.0}])\n",
        "\n",
        "    return imdb_pretty, absa_df\n",
        "\n",
        "def test_load(imdb_display, absa_track, absa_display, imdb_manual, absa_manual):\n",
        "    msgs = []\n",
        "    # IMDb\n",
        "    imdb_dir = (imdb_manual or \"\").strip() or imdb_display_to_path.get(imdb_display or \"\", \"\")\n",
        "    try:\n",
        "        if imdb_dir:\n",
        "            _validate_checkpoint_dir(imdb_dir)\n",
        "            load_model(imdb_dir)\n",
        "            msgs.append(f\"✅ IMDb ok: {imdb_dir}\")\n",
        "        else:\n",
        "            msgs.append(\"ℹ️ IMDb not selected.\")\n",
        "    except Exception as e:\n",
        "        msgs.append(f\"❌ IMDb error: {e}\")\n",
        "\n",
        "    # ABSA\n",
        "    absa_dir = (absa_manual or \"\").strip() or ABSA_FOUND.get(absa_track or \"\", {}).get(absa_display or \"\", \"\")\n",
        "    try:\n",
        "        if absa_dir:\n",
        "            _validate_checkpoint_dir(absa_dir)\n",
        "            load_model(absa_dir)\n",
        "            msgs.append(f\"✅ ABSA ok: {absa_dir}\")\n",
        "        else:\n",
        "            msgs.append(\"ℹ️ ABSA not selected.\")\n",
        "    except Exception as e:\n",
        "        msgs.append(f\"❌ ABSA error: {e}\")\n",
        "\n",
        "    return \"\\n\".join(msgs)"
      ],
      "metadata": {
        "id": "J9__Z1oIQkw-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 8: Colorful CSS (borders & centered title) </h1>"
      ],
      "metadata": {
        "id": "PYSseN-WQlzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "app_css = \"\"\"\n",
        "#app-title { text-align: center; margin-top: 4px; margin-bottom: 16px; }\n",
        ".card {\n",
        "  border: 2px solid #6366f1 !important;   /* indigo */\n",
        "  border-radius: 12px !important;\n",
        "  padding: 10px !important;\n",
        "}\n",
        ".card .gr-textbox, .card .gr-dropdown, .card .gr-slider, .card .gr-dataframe {\n",
        "  border: 1.5px solid #22c55e !important; /* green */\n",
        "  border-radius: 10px !important;\n",
        "}\n",
        ".card label, .card .wrap > label, .card .label-wrap label { font-weight: 600; }\n",
        ".card .gr-dataframe table thead th { background: #eef2ff; }\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JGW-zWXnQ72B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 9: Build the UI </h1>"
      ],
      "metadata": {
        "id": "v4Ipd2_ZRC62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(title=\"IMDb + ABSA Inference\", css=app_css) as demo:\n",
        "    gr.HTML('<h2 id=\"app-title\">IMDb Sentiment (left) + Aspect-Based Sentiment (right)</h2>')\n",
        "    gr.Markdown(\"**Enter a sentence.**\")\n",
        "\n",
        "    with gr.Row():\n",
        "        text_in = gr.Textbox(\n",
        "            label=\"Input text\",\n",
        "            placeholder=\"Type any sentence…\",\n",
        "            lines=3,\n",
        "            elem_classes=[\"card\"]\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left: IMDb\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### IMDb Sentiment\")\n",
        "            imdb_dd = gr.Dropdown(\n",
        "                choices=IMDB_CHOICES,\n",
        "                value=_first_or_blank(IMDB_CHOICES) if IMDB_CHOICES else None,\n",
        "                label=\"IMDb model (best)\",\n",
        "                interactive=True,\n",
        "                allow_custom_value=True,  # you can type if list empty\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "            manual_imdb = gr.Textbox(\n",
        "                label=\"(Optional) IMDb model path (overrides dropdown)\",\n",
        "                placeholder=\"/content/drive/MyDrive/.../best_model\",\n",
        "                lines=1,\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "            imdb_out = gr.Textbox(\n",
        "                label=\"IMDb result\",\n",
        "                value=\"—\",\n",
        "                interactive=False,\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "\n",
        "        # Right: ABSA\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### ABSA (Sentihood)\")\n",
        "            absa_tracks = sorted(list(ABSA_FOUND.keys()))\n",
        "            track_dd = gr.Dropdown(\n",
        "                choices=absa_tracks,\n",
        "                value=_first_or_blank(absa_tracks) if absa_tracks else None,\n",
        "                label=\"ABSA Track\",\n",
        "                interactive=True,\n",
        "                allow_custom_value=True,\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "            absa_models_dd = gr.Dropdown(\n",
        "                choices=absa_model_choices(_first_or_blank(absa_tracks)) if absa_tracks else [],\n",
        "                value=_first_or_blank(absa_model_choices(_first_or_blank(absa_tracks))) if absa_tracks else None,\n",
        "                label=\"ABSA model (best)\",\n",
        "                interactive=True,\n",
        "                allow_custom_value=True,\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "            manual_absa = gr.Textbox(\n",
        "                label=\"(Optional) ABSA model path (overrides dropdown)\",\n",
        "                placeholder=\"/content/drive/MyDrive/ABSA/TrackA/bert-base-uncased/best\",\n",
        "                lines=1,\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                min_conf_sld   = gr.Slider(0.0, 1.0, value=0.60, step=0.01, label=\"Min confidence (keep ≥)\", elem_classes=[\"card\"])\n",
        "                min_margin_sld = gr.Slider(0.0, 1.0, value=0.20, step=0.01, label=\"Min margin vs 'none'\", elem_classes=[\"card\"])\n",
        "                topk_sld       = gr.Slider(1, 20, value=6, step=1, label=\"Top-K rows\", elem_classes=[\"card\"])\n",
        "\n",
        "            absa_df = gr.Dataframe(\n",
        "                headers=[\"Aspect\",\"Target\",\"Label\",\"Confidence\"],\n",
        "                label=\"ABSA output\",\n",
        "                wrap=True,\n",
        "                elem_classes=[\"card\"]\n",
        "            )\n",
        "\n",
        "    with gr.Row():\n",
        "        run_btn  = gr.Button(\"Analyze\")\n",
        "        test_btn = gr.Button(\"Test load\")\n",
        "    diag_out = gr.Markdown()\n",
        "\n",
        "    # Wiring\n",
        "    track_dd.change(on_track_change, inputs=[track_dd], outputs=[absa_models_dd])\n",
        "    run_btn.click(\n",
        "        run_inference,\n",
        "        inputs=[text_in, imdb_dd, track_dd, absa_models_dd, min_conf_sld, min_margin_sld, topk_sld, manual_imdb, manual_absa],\n",
        "        outputs=[imdb_out, absa_df]\n",
        "    )\n",
        "    test_btn.click(\n",
        "        test_load,\n",
        "        inputs=[imdb_dd, track_dd, absa_models_dd, manual_imdb, manual_absa],\n",
        "        outputs=[diag_out]\n",
        "    )"
      ],
      "metadata": {
        "id": "72lT53l4Q7sr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Step 10: Launch </h1>"
      ],
      "metadata": {
        "id": "myQr1xHYRSA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "-0xOKeXpQ7il",
        "outputId": "52fdb846-a2a7-4ae0-d417-8ef5972385de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0ffbc5ba0cfc8d7b13.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0ffbc5ba0cfc8d7b13.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wzpZeAIuo2-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}